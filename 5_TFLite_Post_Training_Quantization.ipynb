{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5_TFLite_Post_Training_Quantization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2uKFqwx7Y5A"
      },
      "source": [
        "## Download Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioLbtB3uGKPX"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akiAa5ypbBHg"
      },
      "source": [
        "## Download the neccessary data into the Colab Instance\r\n",
        "We will split our dataset into three subsets: training set, validation set and testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDRXk6VoccCs",
        "outputId": "2bc40a81-247a-4433-d9ea-c854ae14ce96"
      },
      "source": [
        "import tensorflow_datasets as tfds\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "import os\r\n",
        "\r\n",
        "BATCH_SIZE = 32\r\n",
        "IMAGE_SIZE = 224\r\n",
        "\r\n",
        "def format_image(image, label):\r\n",
        "    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE)) / 255.0\r\n",
        "    return  image, label\r\n",
        "\r\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\r\n",
        "    'cats_vs_dogs',\r\n",
        "    data_dir='/content/dataset/',\r\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\r\n",
        "    with_info=True,\r\n",
        "    shuffle_files=True, \r\n",
        "    as_supervised=True,\r\n",
        ")\r\n",
        "\r\n",
        "# tf.data.experimental.cardinality(raw_train_dataset).numpy()\r\n",
        "num_examples = metadata.splits['train'].num_examples\r\n",
        "num_classes = metadata.features['label'].num_classes\r\n",
        "print(\"Numbers of images: \", num_examples)\r\n",
        "print(\"Numbers of classes: \", num_classes)\r\n",
        "\r\n",
        "train_batches = raw_train.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\r\n",
        "validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\r\n",
        "test_batches = raw_test.map(format_image).batch(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numbers of images:  23262\n",
            "Numbers of classes:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEuJZ6OIbBHl"
      },
      "source": [
        "## Transfer learning\r\n",
        "We download the MobileNet_v2 model and then take the feature extractor from the model. We define our last layer for cat vs dog classification and optimizer for our networks.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PixZ2s5QbYQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50f24d0-362a-4d64-9dbe-6050892ab1d5"
      },
      "source": [
        "IMAGE_SIZE = (224, 224)\n",
        "FV_SIZE = 1280\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=False)\n",
        "\n",
        "feature_extractor = feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=False)\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_2 (KerasLayer)   (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 2,260,546\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GD6WwNXTqTQ"
      },
      "source": [
        "Then, we train our networks within only 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sRB_dmOTqwu"
      },
      "source": [
        "model.compile(optimizer='adam',\r\n",
        "                  loss='sparse_categorical_crossentropy',\r\n",
        "                  metrics=['accuracy'])\r\n",
        "\r\n",
        "EPOCHS = 5\r\n",
        "\r\n",
        "history = model.fit(train_batches,\r\n",
        "                 epochs=EPOCHS,\r\n",
        "                 validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAhmHnBn8RAm"
      },
      "source": [
        "## Run your Tensorflow model\r\n",
        "\r\n",
        "Let's now take a look at actually running a prediction using the model. This code will test 100 images from the testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHkbVcCzBD5W"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "predictions = []\r\n",
        "\r\n",
        "# This will report how many iterations per second, where each\r\n",
        "# iteration is 100 predictions\r\n",
        "test_labels, test_imgs = [], []\r\n",
        "for img, label in tqdm(test_batches.take(100)):\r\n",
        "    predictions.append(model.predict(img))\r\n",
        "    \r\n",
        "    test_labels.append(label.numpy()[0])\r\n",
        "    test_imgs.append(img)\r\n",
        "\r\n",
        "\r\n",
        "# This will tell you how many of the predictions were correct\r\n",
        "score = 0\r\n",
        "for item in range(0,len(predictions)):\r\n",
        "  prediction=np.argmax(predictions[item])\r\n",
        "  label = test_labels[item]\r\n",
        "  if prediction==label:\r\n",
        "    score=score+1\r\n",
        "\r\n",
        "print(\"Out of 100 predictions I got \" + str(score) + \" correct\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45Soe5VoFBv"
      },
      "source": [
        "## Save the Tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_2xbHg6oETp"
      },
      "source": [
        "CATS_VS_DOGS_SAVED_MODEL = \"./exp_saved_model\"\r\n",
        "tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef7KAptqlQPa"
      },
      "source": [
        "import subprocess\r\n",
        "\r\n",
        "def du(path):\r\n",
        "    \"\"\"disk usage in human readable format (e.g. '2,1GB')\"\"\"\r\n",
        "    return subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8')\r\n",
        "# Get file size in bytes for a given model\r\n",
        "print(\"Model size in Mb:\")\r\n",
        "print(du(CATS_VS_DOGS_SAVED_MODEL))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W98lO93EcYoZ"
      },
      "source": [
        "## Convert our model using Tensorflow Lite\r\n",
        "\r\n",
        "We will use Tensorflow Lite to convert our model into a compressed flat buffer, which can be used to deploy on mobile and IoT devices. Here we use post-training quantization (PTQ) and optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ErcJjhqynr"
      },
      "source": [
        "import pathlib\r\n",
        "\r\n",
        "TFLITE_PATH = \"/content/tflite/\"\r\n",
        "TFLITE_NAME = 'model1.tflite'\r\n",
        "tflite_model_file = TFLITE_PATH+TFLITE_NAME\r\n",
        "\r\n",
        "if os.path.isdir(TFLITE_PATH) is False:\r\n",
        "  os.mkdir(TFLITE_PATH)\r\n",
        "\r\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)\r\n",
        "tflite_model = converter.convert()\r\n",
        "\r\n",
        "open(tflite_model_file, \"wb\").write(tflite_model)\r\n",
        "print(\"Tensorflow lite model size in byte: \")\r\n",
        "du(TFLITE_PATH)\r\n",
        "# This will report back the file size in bytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pk26gzgc8zn"
      },
      "source": [
        "## Test Tensorflow Lite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUALX0FWdBgD"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "# Load TFLite model and allocate tensors.\r\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\r\n",
        "interpreter.allocate_tensors()\r\n",
        "\r\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\r\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\r\n",
        "\r\n",
        "predictions = []\r\n",
        "\r\n",
        "# This will report how many iterations per second, where each\r\n",
        "# iteration is 100 predictions\r\n",
        "test_labels, test_imgs = [], []\r\n",
        "for img, label in tqdm(test_batches.take(100)):\r\n",
        "    interpreter.set_tensor(input_index, img)\r\n",
        "    interpreter.invoke()\r\n",
        "    predictions.append(interpreter.get_tensor(output_index))\r\n",
        "    \r\n",
        "    test_labels.append(label.numpy()[0])\r\n",
        "    test_imgs.append(img)\r\n",
        "\r\n",
        "\r\n",
        "# This will tell you how many of the predictions were correct\r\n",
        "score = 0\r\n",
        "for item in range(0,len(predictions)):\r\n",
        "  prediction=np.argmax(predictions[item])\r\n",
        "  label = test_labels[item]\r\n",
        "  if prediction==label:\r\n",
        "    score=score+1\r\n",
        "\r\n",
        "print(\"Out of 100 predictions I got \" + str(score) + \" correct\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0CnEYUYPw4o"
      },
      "source": [
        "##Exercice 1\r\n",
        "How much is the size of the Tensorflow model and those of the Tensorflow Lite model in byte ? \\\\\r\n",
        "\r\n",
        "Is the accuracy of the Tensorflow Lite model not bad ?\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2KspG-bmOcZ"
      },
      "source": [
        "##Exercice 2\r\n",
        "We can try some options:\r\n",
        "\r\n",
        "* By default: Hint : converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n",
        "* Opimization for size: Hint : [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n",
        "* Opimization for latency: Hint : [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\r\n",
        "\r\n",
        "What can we see in term of the size and the accuracy of models ?\r\n",
        "\r\n",
        "To learn more about post-training quantization and optimization, please check out the user guides at https://www.tensorflow.org/lite/performance/post_training_quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4IBgYCYooGD"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Before running the next exercise, run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "651IgjLyo-Jx"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}